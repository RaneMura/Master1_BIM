{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdkvgILA4JHh"
   },
   "source": [
    "<h1><b>Statistique en Bioinformatique : </b> TME8 </h1><br>\n",
    "\n",
    "L’objectif de ce TME est: \n",
    "<br>\n",
    "<ul>\n",
    "<li> Evaluer la performance des HMMs sur les homologues lointains </li> \n",
    "</ul>\n",
    "<br>\n",
    "<div class=\"alert alert-warning\" role=\"alert\" style=\"margin: 10px\">\n",
    "<p><b>Soumission</b></p>\n",
    "<ul>\n",
    "<li>Renomer le fichier TME8.ipynb pour NomEtudiant1_NomEtudiant2.ipynb </li>\n",
    "<li>Soumettre via moodle </li>\n",
    "</div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmRBFyGR4JHm"
   },
   "source": [
    "<h2> Datasets </h2><br>\n",
    "To evaluate the performance of HMMer over remote homologous proteins, we will work with datasets scop-95 and scop-30 having at most 95 and 30% of sequence identity, respectivelly.  We will use a leave-one-out strategy as follows. Given a scop family $F$ in one of the scop datasets, we consider the set of $n$ sequences associated to $F$, to create $n$ test-sets for $F$. Each test-set takes $n−1$ sequences for training and leaves one sequence out for the test. Then, we test whether the sequence that was left out could be annotated by a HMMer profile constructed without using it, and count the correct identification of the domain as a true positive (TP), the identification of an erroneous domain as a false positive (FP) and the identification of no domain as a false negative (FN). For each scop dataset you can find the directory `aln` that contains the alignment for each testsets in STOCKHOLM format, extension .sto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mlYqLoTH4JHn"
   },
   "source": [
    "For scop-95 dataset do:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcUwryMI4JHo"
   },
   "source": [
    "1\\. Create pHMMs from the alignments in `aln/*.sto`. Use the program `hmmbuild` from the HMMer-3 package. Save models  in a directory named models. You have two options (1) do your script in python or (2) in bash script and run it in the terminal.\n",
    "To  built models with python you can use `os.system` to execute hmmbuild program.\n",
    "Anyway, put your code bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eMfsKe2M4JHo"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from os import listdir,system,makedirs\n",
    "from os.path import isfile,join,exists\n",
    "from shutil import rmtree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f0Hs8ilp4JHq"
   },
   "outputs": [],
   "source": [
    "#see run.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CsmzFMty4JHr"
   },
   "source": [
    "2\\. Search all sequences in the file `scopTestSeq.fasta` against all models created previously. Use `hmmsearch` and the option `--domtblout` to save parseable table of per-domain hits to file, use option `-E 1`. Save the outputs in a directory named `searchResults/`. You have two options (1) do your script in python or (2) in bash script and run it in the terminal.\n",
    "To  built models with python you can use `os.system` to execute hmmsearch program.\n",
    "Anyway, put your code bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHulHb154JHs"
   },
   "outputs": [],
   "source": [
    "#see search.sh\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mtG84Mw4JHu"
   },
   "source": [
    "3\\. Concat all search results, rank the sequences and remove all hits having same family and different proteinID. Consider just the best hit per sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FT9iFun4JHv"
   },
   "source": [
    "```bash\n",
    "# the following bash commands illustrate a way to concatenate and format the output of hmmsearch\n",
    "# hmmsearch results are assumed to be in the current directory and in files with extension .out\n",
    "cat *.out > allRes.txt\n",
    "sed '/^#/d' allRes.txt > allRes.txt.ftt\n",
    "cat allRes.txt.ftt | awk '{print $1\" \"$4\" \"$12}' > allRes.txt.ftt.2\n",
    "sed -i -e 's/\\.aln//g' allRes.txt.ftt.2\n",
    "mv allRes.txt.ftt.2 allRes.txt.ftt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0PI0-whR4JHv"
   },
   "outputs": [],
   "source": [
    "#Filter the best hit four each test sequence, you can produce a table with\n",
    "#sequenceID, correct family, predicted family\n",
    "\n",
    "def removeWrongLines(nom):\n",
    "\tinfile=open(nom, 'r')\n",
    "\toutfile=open(nom + \".tmp\", 'w')\n",
    "\tA=infile.readlines()\n",
    "\trep = \"\"\n",
    "\tcpt=0\n",
    "\tfor ligne in A :\n",
    "\t\tif ligne[0] != \"#\": \n",
    "\t\t\ttab=ligne.split()\n",
    "\t\t\tprot = tab[0]; protqid = prot[0:7]; protqfa = prot[7:]\n",
    "\t\t\tprot = tab[1]; protmid = prot[0:7]; protmfa = prot[7:]\n",
    "\t\t\tif (protqfa != protmfa) :\n",
    "\t\t\t\trep= rep + ligne\n",
    "\t\t\telif (protqid == protmid):\n",
    "\t\t\t\trep= rep + ligne\n",
    "\t\n",
    "\toutfile.write(rep)\n",
    "\toutfile.close()\n",
    "\tinfile.close()\n",
    " \n",
    "################################################\n",
    "def removeDupLines(nom):\n",
    "\tinfile=open(nom, 'r')\n",
    "\tA=infile.readlines()\n",
    "\trep = {}\n",
    "\tlrep = []\n",
    "\tcpt=0\n",
    "\tfor ligne in A :\n",
    "\t\ttab=ligne.split()\n",
    "\t\tprot = tab[0]; protqid = prot[0:7]; protqfa = prot[7:]\n",
    "\t\tprot = tab[1]; protmid = prot[0:7]; protmfa = prot[7:]\n",
    "\t\tevalue = float(tab[2])\n",
    "\t\tl=[]\n",
    "\t\tif protqid not in rep.keys():\n",
    "\t\t\tl.append(protqid); l.append(protqfa); l.append(protmid); l.append(protmfa); l.append(evalue);\n",
    "\t\telse:\n",
    "\t\t\tc = rep[protqid]\n",
    "\t\t\t#print c\n",
    "\t\t\tif (evalue < c[4]):\n",
    "\t\t\t\tl.append(protqid);l.append(protqfa); l.append(protmid); l.append(protmfa); l.append(evalue);\n",
    "\t\t\telse:\n",
    "\t\t\t\tl = c\n",
    "\t\trep[protqid] = l\n",
    "\t\n",
    "\tfor key in rep:\n",
    "\t\tlrep.append(rep[key])\n",
    "\treturn lrep\t\n",
    "\n",
    "file = \"allRes.txt.ftt\"\n",
    "removeWrongLines(file)\n",
    "rep = removeDupLines(file + \".tmp\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjkfA1di4JHw"
   },
   "source": [
    "4\\. Compute the performance. If a test sequence is better scored by the model associated to its family it is a true positive (TP). If it is scored by a different model it is a false positive (FP). If it is not scored by any model it is a false negative (FN). With this values compute $\\text{Precision}=\\frac{TP}{TP+FP}$, $\\text{Recall} = \\frac{TP}{TP+FN}$, and $\\text{F-score} = \\frac{ 2 \\cdot \\text{Precision} \\cdot \\text{Recall} }{ \\text{Precision} + \\text{Recall} }$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7TIB6Mps4JHw"
   },
   "outputs": [],
   "source": [
    "def ComputePerformance(resultsTable):\n",
    "    \"\"\"\n",
    "    compute performance measures\n",
    "\n",
    "    \"\"\"\n",
    "    TP,FP,FN = 0,0,0       \n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    f_score = 2*precision*recall / (precision+recall)\n",
    "    \n",
    "    \n",
    "    return TP,FP,FN,precision,recall,f_score\n",
    "\n",
    "\n",
    "TP,FP,FN,precision,recall,f_score = ComputePerformance(rep) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJNKTq-04JHx"
   },
   "source": [
    "5\\. Roc curve https://en.wikipedia.org/wiki/Receiver_operating_characteristic. We can plot curves to observe the performance of a tool under different conditions. For that, we range the score (E-value) and we compute true positive rate (Y axis) and false positive rate (X-axis) measures for each value. Write a python script to construct the Roc curve based on the results obtained before.<br><br>\n",
    "\n",
    "<font color=\"blue\">\n",
    "Sensitivity = true positive rate, recall, or probability of detection = the proportion of positives that are correctly classified\n",
    "Specificity = true negative rate = the proportion of negatives that are correctly classified\n",
    "<br>\n",
    "<br>\n",
    "$\\text{True Positive Rate} = \\frac{TP}{TP+FN}$\n",
    "<br>\n",
    "<br>\n",
    "$\\text{False Positive Rate} = \\frac{FP}{FP+TN}$\n",
    "<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gQC4b1h-4JHx"
   },
   "outputs": [],
   "source": [
    "def plorROC(rep, nom, total):\n",
    "  pass\n",
    "\n",
    "\n",
    "plorROC(rep, \"Scop-95\", 789)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jl5S7f5o4JHy"
   },
   "source": [
    "6\\. Write a python script to plot the Precision/recall curve. We can use the same strategy of Roc curve to compute the precision  (Y axis)  and recall  (X axis)  curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9WdrokDt4JHy"
   },
   "outputs": [],
   "source": [
    "def plotPR(reps, nom, total):\n",
    "  pass\n",
    "    \n",
    "        \n",
    "plotPR(rep, \"Scop-95\", 789)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkanuAua4JHy"
   },
   "source": [
    "7\\. Repeat steps 1 to 6 also for the scop-30 dataset and compare the curves obtained for the two SCOP datasets, what is your conclusion? Include the curves in your answer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_NP2nkk4JHz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "texvNBz14JHz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbMNNVGM4JH0",
    "outputId": "1c88341d-da08-4060-d610-20c1ab59b883"
   },
   "source": [
    "<font color=\"blue\">\n",
    "Conclusion \n",
    "<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eevn4BVZZS_1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
